{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "\n"}, {"metadata": {}, "cell_type": "markdown", "source": "In this notebook, we will use use the Keras library to build convolutional neural networks. I will use the popular MNIST dataset and  compare results to using a conventional neural network.\n"}, {"metadata": {}, "cell_type": "markdown", "source": ""}, {"metadata": {}, "cell_type": "markdown", "source": ""}, {"metadata": {}, "cell_type": "markdown", "source": "<a id='item41'></a>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Import Keras and Packages\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"}, {"metadata": {}, "cell_type": "code", "source": "import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical", "execution_count": 1, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Using TensorFlow backend.\n/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "When working with convolutional neural networks in particular, we will need additional packages.\n"}, {"metadata": {}, "cell_type": "code", "source": "from keras.layers.convolutional import Conv2D # to add convolutional layers\nfrom keras.layers.convolutional import MaxPooling2D # to add pooling layers\nfrom keras.layers import Flatten # to flatten data for fully connected layers", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id='item42'></a>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Convolutional Layer with One set of convolutional and pooling layers\n"}, {"metadata": {}, "cell_type": "code", "source": "# import data\nfrom keras.datasets import mnist\n\n# load data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n# reshape to be [samples][pixels][width][height]\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')", "execution_count": 3, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n11493376/11490434 [==============================] - 1s 0us/step\n"}]}, {"metadata": {}, "cell_type": "code", "source": "X_test.shape", "execution_count": 5, "outputs": [{"data": {"text/plain": "(10000, 28, 28, 1)"}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Let's normalize the pixel values to be between 0 and 1\n"}, {"metadata": {}, "cell_type": "code", "source": "X_train = X_train / 255 # normalize training data\nX_test = X_test / 255 # normalize test data", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Next, let's convert the target variable into binary categories\n"}, {"metadata": {}, "cell_type": "code", "source": "y_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\nnum_classes = y_test.shape[1] # number of categories", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "y_test.shape", "execution_count": 8, "outputs": [{"data": {"text/plain": "(10000, 10)"}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Next, let's define a function that creates our model. Let's start with one set of convolutional and pooling layers.\n"}, {"metadata": {}, "cell_type": "code", "source": "def convolutional_model():\n    \n    # create model\n    model = Sequential()\n    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    \n    model.add(Flatten())\n    model.add(Dense(100, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    \n    # compile model\n    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n    return model", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Finally, let's call the function to create the model, and then let's train it and evaluate it.\n"}, {"metadata": {}, "cell_type": "code", "source": "# build the model\nmodel = convolutional_model()\n\n# fit the model\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n\n# evaluate the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))", "execution_count": 10, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/10\n - 267s - loss: 0.3001 - acc: 0.9176 - val_loss: 0.1054 - val_acc: 0.9701\nEpoch 2/10\n - 265s - loss: 0.0853 - acc: 0.9743 - val_loss: 0.0693 - val_acc: 0.9775\nEpoch 3/10\n - 264s - loss: 0.0607 - acc: 0.9815 - val_loss: 0.0515 - val_acc: 0.9832\nEpoch 4/10\n - 255s - loss: 0.0487 - acc: 0.9854 - val_loss: 0.0450 - val_acc: 0.9852\nEpoch 5/10\n - 277s - loss: 0.0394 - acc: 0.9881 - val_loss: 0.0443 - val_acc: 0.9853\nEpoch 6/10\n - 266s - loss: 0.0332 - acc: 0.9899 - val_loss: 0.0395 - val_acc: 0.9858\nEpoch 7/10\n - 264s - loss: 0.0282 - acc: 0.9912 - val_loss: 0.0413 - val_acc: 0.9858\nEpoch 8/10\n - 267s - loss: 0.0231 - acc: 0.9928 - val_loss: 0.0442 - val_acc: 0.9852\nEpoch 9/10\n - 268s - loss: 0.0202 - acc: 0.9940 - val_loss: 0.0389 - val_acc: 0.9872\nEpoch 10/10\n - 273s - loss: 0.0172 - acc: 0.9948 - val_loss: 0.0402 - val_acc: 0.9882\nAccuracy: 0.9882 \n Error: 1.1800000000000068\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "* * *\n"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id='item43'></a>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Convolutional Layer with two sets of convolutional and pooling layers\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Let's redefine our convolutional model so that it has two convolutional and pooling layers instead of just one layer of each.\n"}, {"metadata": {}, "cell_type": "code", "source": "def convolutional_model():\n    \n    # create model\n    model = Sequential()\n    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    \n    model.add(Conv2D(8, (2, 2), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    \n    model.add(Flatten())\n    model.add(Dense(100, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    \n    # Compile model\n    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n    return model", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it.\n"}, {"metadata": {}, "cell_type": "code", "source": "# build the model\nmodel = convolutional_model()\n\n# fit the model\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n\n# evaluate the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ""}, {"metadata": {}, "cell_type": "markdown", "source": ""}, {"metadata": {}, "cell_type": "markdown", "source": ""}, {"metadata": {}, "cell_type": "markdown", "source": ""}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.7", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}